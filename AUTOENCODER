from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Conv2DTranspose
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Reshape
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K
import numpy as np
def build(width, height, depth, filters=(32, 64), latentDim=16):
  # initialize the input shape to be "channels last" along with
  # the channels dimension itself
  # channels dimension itself
  inputShape = (height, width, depth)
  chanDim = -1
  # define the input to the encoder
  inputs = Input(shape=inputShape)
  x = inputs
  # loop over the number of filters
  for f in filters:
    # apply a CONV => RELU => BN operation
    x = Conv2D(f, (3, 3), strides=2, padding="same")(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization(axis=chanDim)(x)
  # flatten the network and then construct our latent vector
  volumeSize = K.int_shape(x)
  x = Flatten()(x)
  latent = Dense(latentDim)(x)
  # build the encoder model
  encoder = Model(inputs, latent, name="encoder")#encoder.summary()
  # start building the decoder model which will accept the
  # output of the encoder as its inputs
  latentInputs = Input(shape=(latentDim,))
  x = Dense(np.prod(volumeSize[1:]))(latentInputs)
  x = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)
  # loop over our number of filters again, but this time in
  # reverse order
  for f in filters[::-1]:
    # apply a CONV_TRANSPOSE => RELU => BN operation
    x = Conv2DTranspose(f, (3, 3), strides=2,
      padding="same")(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization(axis=chanDim)(x)
    # apply a single CONV_TRANSPOSE layer used to recover the
  # original depth of the image
  x = Conv2DTranspose(depth, (3, 3), padding="same")(x)
  outputs = Activation("sigmoid")(x)
  # build the decoder model
  decoder = Model(latentInputs, outputs, name="decoder")
  # our autoencoder is the encoder + decoder
  autoencoder = Model(inputs, decoder(encoder(inputs)),name="autoencoder")
  # return a 3-tuple of the encoder, decoder, and autoencoder
  return (encoder, decoder, autoencoder)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.datasets import mnist
import matplotlib.pyplot as plt
import numpy as np
import cv2
# initialize the number of epochs to train for and batch size
EPOCHS = 25
BS = 32
# load the MNIST dataset
print("[INFO] loading MNIST dataset...")
((trainX, _), (testX, _)) = mnist.load_data()
# add a channel dimension to every image in the dataset, then scale
# the pixel intensities to the range [0, 1]
trainX = np.expand_dims(trainX, axis=-1)
testX = np.expand_dims(testX, axis=-1)
trainX = trainX.astype("float32") / 255.0
testX = testX.astype("float32") / 255.0
[INFO] loading MNIST dataset...
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11490434/11490434 [==============================] - 0s 0us/step
# sample noise from a random normal distribution centered at 0.5 (since
# our images lie in the range [0, 1]) and a standard deviation of 0.5
trainNoise = np.random.normal(loc=0.5, scale=0.5, size=trainX.shape)
testNoise = np.random.normal(loc=0.5, scale=0.5, size=testX.shape)
trainXNoisy = np.clip(trainX + trainNoise, 0, 1)
testXNoisy = np.clip(testX + testNoise, 0, 1)
from google.colab.patches import cv2_imshow
cv2_imshow((testXNoisy[1] * 255).astype("uint8"))

cv2_imshow((testX[1]* 255).astype("uint8"))

#construct our convolutional autoencoder
print("[INFO] building autoencoder...")
(encoder, decoder, autoencoder) = build(28, 28, 1)
opt = Adam(learning_rate=1e-3)
autoencoder.compile(loss="mse", optimizer=opt)
[INFO] building autoencoder...
autoencoder.summary()
Model: "autoencoder"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 28, 28, 1)]       0         
                                                                 
 encoder (Functional)        (None, 16)                69392     
                                                                 
 decoder (Functional)        (None, 28, 28, 1)         109377    
                                                                 
=================================================================
Total params: 178,769
Trainable params: 178,385
Non-trainable params: 384
_________________________________________________________________
# train the convolutional autoencoder
H = autoencoder.fit(trainXNoisy, trainX,validation_data=(testXNoisy, testX),epochs=EPOCHS,batch_size=BS)
Epoch 1/25
1875/1875 [==============================] - 17s 5ms/step - loss: 0.0280 - val_loss: 0.0194
Epoch 2/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0188 - val_loss: 0.0178
Epoch 3/25
1875/1875 [==============================] - 8s 4ms/step - loss: 0.0177 - val_loss: 0.0183
Epoch 4/25
1875/1875 [==============================] - 8s 4ms/step - loss: 0.0172 - val_loss: 0.0174
Epoch 5/25
1875/1875 [==============================] - 8s 4ms/step - loss: 0.0167 - val_loss: 0.0168
Epoch 6/25
1875/1875 [==============================] - 8s 4ms/step - loss: 0.0164 - val_loss: 0.0165
Epoch 7/25
1875/1875 [==============================] - 8s 4ms/step - loss: 0.0162 - val_loss: 0.0173
Epoch 8/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0160 - val_loss: 0.0162
Epoch 9/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0158 - val_loss: 0.0167
Epoch 10/25
1875/1875 [==============================] - 8s 4ms/step - loss: 0.0157 - val_loss: 0.0159
Epoch 11/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0155 - val_loss: 0.0165
Epoch 12/25
1875/1875 [==============================] - 8s 4ms/step - loss: 0.0154 - val_loss: 0.0158
Epoch 13/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0153 - val_loss: 0.0160
Epoch 14/25
1875/1875 [==============================] - 8s 4ms/step - loss: 0.0152 - val_loss: 0.0161
Epoch 15/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0151 - val_loss: 0.0158
Epoch 16/25
1875/1875 [==============================] - 8s 4ms/step - loss: 0.0150 - val_loss: 0.0160
Epoch 17/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0149 - val_loss: 0.0163
Epoch 18/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0149 - val_loss: 0.0169
Epoch 19/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0148 - val_loss: 0.0156
Epoch 20/25
1875/1875 [==============================] - 8s 4ms/step - loss: 0.0147 - val_loss: 0.0159
Epoch 21/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0147 - val_loss: 0.0159
Epoch 22/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0146 - val_loss: 0.0155
Epoch 23/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0146 - val_loss: 0.0154
Epoch 24/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0145 - val_loss: 0.0157
Epoch 25/25
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0145 - val_loss: 0.0155
# construct a plot that plots and saves the training history
N = np.arange(0, EPOCHS)
plt.style.use("ggplot")
plt.figure()
plt.plot(N, H.history["loss"], label="train_loss")
plt.plot(N, H.history["val_loss"], label="val_loss")
plt.title("Training Loss and Accuracy")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend(loc="lower left")
#plt.savefig("/content/loss.png")

# use the convolutional autoencoder to make predictions on the
# testing images, then initialize our list of output images
print("[INFO] making predictions...")
decoded = autoencoder.predict(testX)
outputs = None
# loop over our number of output samples
for i in range(0, 10):
	# grab the original image and reconstructed image
	original = (testXNoisy[i] * 255).astype("uint8")
	recon = (decoded[i] * 255).astype("uint8")
	# stack the original and reconstructed image side-by-side
	output = np.hstack([original, recon])
	# if the outputs array is empty, initialize it as the current
	# side-by-side image display
	if outputs is None:
		outputs = output
	# otherwise, vertically stack the outputs
	else:
		outputs = np.vstack([outputs, output])
# save the outputs image to disk
cv2_imshow(outputs)
[INFO] making predictions...
313/313 [==============================] - 1s 2ms/step
